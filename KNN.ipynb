{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Convert import convert_to_dataframe, single_y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "iris = convert_to_dataframe(load_iris())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "     sepallength  sepalwidth  petallength  petalwidth      target\n103          6.3         2.9          5.6         1.8   virginica\n4            5.0         3.6          1.4         0.2      setosa\n68           6.2         2.2          4.5         1.5  versicolor\n39           5.1         3.4          1.5         0.2      setosa\n75           6.6         3.0          4.4         1.4  versicolor\n95           5.7         3.0          4.2         1.2  versicolor\n11           4.8         3.4          1.6         0.2      setosa\n104          6.5         3.0          5.8         2.2   virginica\n42           4.4         3.2          1.3         0.2      setosa\n106          4.9         2.5          4.5         1.7   virginica",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepallength</th>\n      <th>sepalwidth</th>\n      <th>petallength</th>\n      <th>petalwidth</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>103</th>\n      <td>6.3</td>\n      <td>2.9</td>\n      <td>5.6</td>\n      <td>1.8</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>68</th>\n      <td>6.2</td>\n      <td>2.2</td>\n      <td>4.5</td>\n      <td>1.5</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>5.1</td>\n      <td>3.4</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>75</th>\n      <td>6.6</td>\n      <td>3.0</td>\n      <td>4.4</td>\n      <td>1.4</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>95</th>\n      <td>5.7</td>\n      <td>3.0</td>\n      <td>4.2</td>\n      <td>1.2</td>\n      <td>versicolor</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4.8</td>\n      <td>3.4</td>\n      <td>1.6</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>104</th>\n      <td>6.5</td>\n      <td>3.0</td>\n      <td>5.8</td>\n      <td>2.2</td>\n      <td>virginica</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>4.4</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>106</th>\n      <td>4.9</td>\n      <td>2.5</td>\n      <td>4.5</td>\n      <td>1.7</td>\n      <td>virginica</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.sample(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepallength', 'sepalwidth', 'petallength', 'petalwidth']\n",
      "['setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "X = iris.drop(['target'], axis=1)\n",
    "Y = iris['target']\n",
    "feature_names = iris.columns.values.tolist()[:-1]\n",
    "class_names = Y.unique().tolist()\n",
    "print(feature_names)\n",
    "print(class_names)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "     sepallength  sepalwidth  petallength  petalwidth\n145          6.7         3.0          5.2         2.3\n121          5.6         2.8          4.9         2.0\n51           6.4         3.2          4.5         1.5\n109          7.2         3.6          6.1         2.5\n47           4.6         3.2          1.4         0.2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepallength</th>\n      <th>sepalwidth</th>\n      <th>petallength</th>\n      <th>petalwidth</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>145</th>\n      <td>6.7</td>\n      <td>3.0</td>\n      <td>5.2</td>\n      <td>2.3</td>\n    </tr>\n    <tr>\n      <th>121</th>\n      <td>5.6</td>\n      <td>2.8</td>\n      <td>4.9</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>6.4</td>\n      <td>3.2</td>\n      <td>4.5</td>\n      <td>1.5</td>\n    </tr>\n    <tr>\n      <th>109</th>\n      <td>7.2</td>\n      <td>3.6</td>\n      <td>6.1</td>\n      <td>2.5</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>4.6</td>\n      <td>3.2</td>\n      <td>1.4</td>\n      <td>0.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "clf = clf.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    index      target      y_pred\n",
      "0      49      setosa      setosa\n",
      "1      30      setosa      setosa\n",
      "2      40      setosa      setosa\n",
      "3      70  versicolor  versicolor\n",
      "4     138   virginica   virginica\n",
      "5     114   virginica   virginica\n",
      "6      75  versicolor  versicolor\n",
      "7       4      setosa      setosa\n",
      "8      88  versicolor  versicolor\n",
      "9      97  versicolor  versicolor\n",
      "10      3      setosa      setosa\n",
      "11     16      setosa      setosa\n",
      "12     80  versicolor  versicolor\n",
      "13      0      setosa      setosa\n",
      "14     41      setosa      setosa\n",
      "15    127   virginica   virginica\n",
      "16    129   virginica   virginica\n",
      "17     28      setosa      setosa\n",
      "18     14      setosa      setosa\n",
      "19     53  versicolor  versicolor\n",
      "20     61  versicolor  versicolor\n",
      "21     54  versicolor  versicolor\n",
      "22    125   virginica   virginica\n",
      "23    136   virginica   virginica\n",
      "24     17      setosa      setosa\n",
      "25      9      setosa      setosa\n",
      "26     62  versicolor  versicolor\n",
      "27    147   virginica   virginica\n",
      "28    142   virginica   virginica\n",
      "29    133   virginica  versicolor\n"
     ]
    }
   ],
   "source": [
    "print(single_y_test_pred(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        12\n",
      "  versicolor       0.90      1.00      0.95         9\n",
      "   virginica       1.00      0.89      0.94         9\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.96      0.96        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[12  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  1  8]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, y_pred, labels=class_names))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.67% on Test Data\n",
      "Accuracy: 96.67% on Training Data\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = metrics.accuracy_score(y_test, y_pred) * 100\n",
    "accuracy_train = metrics.accuracy_score(y_train, clf.predict(x_train)) * 100\n",
    "\n",
    "print(f\"Accuracy: {round(accuracy_test, 2)}% on Test Data\")\n",
    "print(f\"Accuracy: {round(accuracy_train, 2)}% on Training Data\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9666666666666667"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[0.24494897, 0.36055513, 0.37416574, 0.37416574, 0.42426407],\n        [0.31622777, 0.33166248, 0.45825757, 0.60827625, 0.64031242],\n        [0.26457513, 0.34641016, 0.37416574, 0.38729833, 0.41231056],\n        [0.63245553, 0.67082039, 0.70710678, 0.75498344, 0.80622577],\n        [0.14142136, 0.2236068 , 0.2236068 , 0.2236068 , 0.3       ],\n        [0.14142136, 0.26457513, 0.28284271, 0.3       , 0.34641016],\n        [0.31622777, 0.37416574, 0.42426407, 0.42426407, 0.51961524],\n        [0.14142136, 0.26457513, 0.26457513, 0.26457513, 0.3       ],\n        [0.1       , 0.31622777, 0.33166248, 0.37416574, 0.38729833],\n        [0.1       , 0.28284271, 0.3       , 0.33166248, 0.33166248],\n        [0.2       , 0.2236068 , 0.2236068 , 0.24494897, 0.28284271],\n        [0.37416574, 0.42426407, 0.42426407, 0.46904158, 0.48989795],\n        [0.26457513, 0.31622777, 0.42426407, 0.42426407, 0.42426407],\n        [0.26457513, 0.28284271, 0.31622777, 0.34641016, 0.50990195],\n        [0.53851648, 0.55677644, 0.66332496, 0.7       , 0.71414284],\n        [0.2236068 , 0.2236068 , 0.24494897, 0.3       , 0.31622777],\n        [0.5       , 0.50990195, 0.55677644, 0.60827625, 0.64031242],\n        [0.37416574, 0.45825757, 0.46904158, 0.50990195, 0.57445626],\n        [0.26457513, 0.34641016, 0.43588989, 0.50990195, 0.50990195],\n        [0.2       , 0.26457513, 0.37416574, 0.38729833, 0.38729833],\n        [0.14142136, 0.2       , 0.24494897, 0.3       , 0.36055513],\n        [0.36055513, 0.38729833, 0.41231056, 0.43588989, 0.4472136 ],\n        [0.24494897, 0.3       , 0.31622777, 0.4       , 0.47958315],\n        [0.14142136, 0.31622777, 0.34641016, 0.36055513, 0.42426407],\n        [0.42426407, 0.4472136 , 0.51961524, 0.53851648, 0.54772256],\n        [0.2       , 0.24494897, 0.37416574, 0.38729833, 0.41231056],\n        [0.33166248, 0.38729833, 0.46904158, 0.50990195, 0.54772256],\n        [0.24494897, 0.26457513, 0.34641016, 0.34641016, 0.36055513],\n        [0.38729833, 0.38729833, 0.72111026, 0.79372539, 0.81853528],\n        [0.17320508, 0.36055513, 0.36055513, 0.37416574, 0.41231056],\n        [0.26457513, 0.57445626, 0.6164414 , 0.6244998 , 0.67082039],\n        [0.14142136, 0.24494897, 0.38729833, 0.38729833, 0.42426407],\n        [0.14142136, 0.24494897, 0.33166248, 0.37416574, 0.38729833],\n        [0.26457513, 0.33166248, 0.54772256, 0.58309519, 0.60827625],\n        [0.28284271, 0.31622777, 0.31622777, 0.33166248, 0.34641016],\n        [0.26457513, 0.33166248, 0.43588989, 0.45825757, 0.51961524],\n        [0.26457513, 0.31622777, 0.31622777, 0.34641016, 0.36055513],\n        [0.2236068 , 0.3       , 0.38729833, 0.45825757, 0.50990195],\n        [0.36055513, 0.37416574, 0.41231056, 0.41231056, 0.47958315],\n        [0.45825757, 0.50990195, 0.50990195, 0.53851648, 0.56568542],\n        [0.3       , 0.37416574, 0.41231056, 0.4472136 , 0.47958315],\n        [0.31622777, 0.31622777, 0.34641016, 0.38729833, 0.43588989],\n        [0.2       , 0.3       , 0.38729833, 0.41231056, 0.43588989],\n        [0.26457513, 0.50990195, 0.53851648, 0.70710678, 0.71414284],\n        [0.14142136, 0.2236068 , 0.2236068 , 0.28284271, 0.3       ],\n        [0.14142136, 0.14142136, 0.14142136, 0.2236068 , 0.3       ],\n        [0.73484692, 0.76157731, 0.79372539, 0.87749644, 0.88317609],\n        [0.14142136, 0.24494897, 0.24494897, 0.33166248, 0.33166248],\n        [0.24494897, 0.24494897, 0.33166248, 0.38729833, 0.42426407],\n        [0.14142136, 0.17320508, 0.24494897, 0.26457513, 0.26457513],\n        [0.3       , 0.31622777, 0.33166248, 0.36055513, 0.36055513],\n        [0.26457513, 0.31622777, 0.33166248, 0.36055513, 0.51961524],\n        [0.17320508, 0.2236068 , 0.26457513, 0.3       , 0.31622777],\n        [0.34641016, 0.34641016, 0.37416574, 0.42426407, 0.45825757],\n        [0.14142136, 0.14142136, 0.24494897, 0.33166248, 0.33166248],\n        [0.26457513, 0.52915026, 0.54772256, 0.60827625, 0.678233  ],\n        [0.26457513, 0.41231056, 0.60827625, 0.678233  , 0.7       ],\n        [0.3       , 0.31622777, 0.36055513, 0.38729833, 0.38729833],\n        [0.24494897, 0.31622777, 0.34641016, 0.47958315, 0.5       ],\n        [0.34641016, 0.43588989, 0.4472136 , 0.46904158, 0.54772256],\n        [0.3       , 0.31622777, 0.37416574, 0.37416574, 0.38729833],\n        [0.3       , 0.31622777, 0.34641016, 0.36055513, 0.42426407],\n        [0.36055513, 0.45825757, 0.67082039, 0.72111026, 0.88317609],\n        [0.55677644, 0.6       , 0.6164414 , 0.6164414 , 0.6244998 ],\n        [0.14142136, 0.17320508, 0.2       , 0.2       , 0.24494897],\n        [0.24494897, 0.36055513, 0.46904158, 0.50990195, 0.54772256],\n        [0.36055513, 0.41231056, 0.42426407, 0.43588989, 0.4472136 ],\n        [0.36055513, 0.6164414 , 0.64031242, 0.65574385, 0.78740079],\n        [0.14142136, 0.2       , 0.3       , 0.38729833, 0.42426407],\n        [0.41231056, 0.54772256, 0.89442719, 0.92736185, 0.96436508],\n        [0.14142136, 0.24494897, 0.28284271, 0.3       , 0.31622777],\n        [0.2236068 , 0.2236068 , 0.28284271, 0.3       , 0.3       ],\n        [0.17320508, 0.2236068 , 0.3       , 0.3       , 0.36055513],\n        [0.43588989, 0.51961524, 0.53851648, 0.58309519, 0.65574385],\n        [0.1       , 0.14142136, 0.24494897, 0.31622777, 0.31622777],\n        [0.1       , 0.2236068 , 0.24494897, 0.24494897, 0.28284271],\n        [0.14142136, 0.2236068 , 0.24494897, 0.43588989, 0.46904158],\n        [0.17320508, 0.24494897, 0.36055513, 0.41231056, 0.42426407],\n        [0.2       , 0.41231056, 0.47958315, 0.50990195, 0.51961524],\n        [0.14142136, 0.38729833, 0.45825757, 0.72111026, 0.83666003],\n        [0.17320508, 0.34641016, 0.36055513, 0.37416574, 0.37416574],\n        [0.1       , 0.2236068 , 0.2236068 , 0.2236068 , 0.26457513],\n        [0.14142136, 0.24494897, 0.43588989, 0.45825757, 0.46904158],\n        [0.24494897, 0.3       , 0.33166248, 0.37416574, 0.38729833],\n        [0.37416574, 0.37416574, 0.38729833, 0.38729833, 0.42426407],\n        [0.26457513, 0.52915026, 0.54772256, 0.54772256, 0.60827625],\n        [0.41231056, 0.88317609, 0.92736185, 0.93273791, 1.06301458],\n        [0.3       , 0.37416574, 0.37416574, 0.4472136 , 0.50990195],\n        [0.3       , 0.31622777, 0.31622777, 0.33166248, 0.37416574],\n        [0.4       , 0.41231056, 0.45825757, 0.5       , 0.53851648],\n        [0.14142136, 0.2       , 0.2       , 0.26457513, 0.3       ],\n        [0.2236068 , 0.26457513, 0.31622777, 0.42426407, 0.43588989],\n        [0.14142136, 0.24494897, 0.26457513, 0.26457513, 0.31622777],\n        [0.2236068 , 0.31622777, 0.31622777, 0.34641016, 0.38729833],\n        [0.33166248, 0.37416574, 0.45825757, 0.46904158, 0.53851648],\n        [0.2236068 , 0.26457513, 0.3       , 0.31622777, 0.31622777],\n        [0.24494897, 0.26457513, 0.26457513, 0.3       , 0.36055513],\n        [0.36055513, 0.37416574, 0.41231056, 0.42426407, 0.42426407],\n        [0.3       , 0.55677644, 0.6244998 , 0.6244998 , 0.6244998 ],\n        [0.31622777, 0.34641016, 0.34641016, 0.42426407, 0.45825757],\n        [0.33166248, 0.34641016, 0.36055513, 0.37416574, 0.38729833],\n        [0.38729833, 0.50990195, 0.53851648, 0.54772256, 0.55677644],\n        [0.17320508, 0.38729833, 0.42426407, 0.43588989, 0.4472136 ],\n        [0.2       , 0.2236068 , 0.3       , 0.31622777, 0.31622777],\n        [0.2236068 , 0.26457513, 0.3       , 0.3       , 0.36055513],\n        [0.34641016, 0.37416574, 0.41231056, 0.43588989, 0.4472136 ],\n        [0.53851648, 0.54772256, 0.66332496, 0.678233  , 0.7       ],\n        [0.41231056, 0.81853528, 0.86023253, 1.00498756, 1.0198039 ],\n        [0.14142136, 0.36055513, 0.38729833, 0.64807407, 0.78740079],\n        [0.14142136, 0.2       , 0.2       , 0.26457513, 0.3       ],\n        [0.14142136, 0.14142136, 0.2236068 , 0.31622777, 0.38729833],\n        [0.28284271, 0.3       , 0.36055513, 0.36055513, 0.37416574],\n        [0.34641016, 0.36055513, 0.47958315, 0.51961524, 0.54772256],\n        [0.24494897, 0.37416574, 0.38729833, 0.41231056, 0.47958315],\n        [0.26457513, 0.45825757, 0.53851648, 0.60827625, 0.678233  ],\n        [0.26457513, 0.37416574, 0.42426407, 0.45825757, 0.48989795],\n        [0.1       , 0.3       , 0.42426407, 0.43588989, 0.46904158],\n        [0.28284271, 0.3       , 0.31622777, 0.36055513, 0.36055513],\n        [0.31622777, 0.31622777, 0.31622777, 0.36055513, 0.42426407],\n        [0.24494897, 0.28284271, 0.33166248, 0.36055513, 0.37416574]]),\n array([[ 65,  29,  80,  87,  27],\n        [ 51,  33,  94,  97, 102],\n        [115,  41,  34,  68,  21],\n        [ 93, 104,  22,  89, 106],\n        [  7, 103,  95,  15,  20],\n        [ 92,  49, 119,  96, 105],\n        [ 13,  34,  11,  99,  77],\n        [  4,  95,  90, 109, 103],\n        [116,  57,  48,  84,  31],\n        [ 75,  44,  61,  54,  47],\n        [ 19,  91,  81,  74,  71],\n        [ 87,   6,   0,  82,  31],\n        [ 52,  88, 110,  83,  49],\n        [ 35,  34,   6,  99, 118],\n        [ 48,  97,  84,  31,  82],\n        [ 71,   4,  64,   7,  95],\n        [ 22,  57,  93,  27,  60],\n        [115,   2,  68,  25,  42],\n        [ 96,  59,  83,  92,   5],\n        [ 10,  91,  74,  81, 117],\n        [ 23, 103,  58,   4,   7],\n        [118,  41,   2, 105,  68],\n        [ 27, 104,  93,  60,  57],\n        [ 20, 103,  58,   4, 109],\n        [  5,  59,  49,  96, 101],\n        [ 68,  76,  88,  37,  42],\n        [100,   9,  75, 111, 117],\n        [ 22, 104,  80,  93,  57],\n        [ 79, 108,  62,  59,  18],\n        [ 80,   0,  65, 104,  27],\n        [ 43,  66,  21,  37, 105],\n        [ 82,  48,  84,   8,  80],\n        [110,  49,  52,  88, 119],\n        [ 51,   1,  97,  94, 113],\n        [ 13,  41, 118,  35,  99],\n        [ 13,  34,  41,  99, 118],\n        [ 81,  74,  71,  44,  54],\n        [ 76,  68,  25,  88,  66],\n        [ 47, 100,  70,  54,  91],\n        [ 95,   7,  36, 103,   4],\n        [ 71,  15,  10,  81,  19],\n        [118,  34,   2,  21,  35],\n        [ 78,  88, 110,  25,  32],\n        [ 30,  66,  73,  37, 113],\n        [ 74,  75,  81,   9, 111],\n        [ 64, 109,  90,  72,  50],\n        [ 78, 101,  12,  83,  52],\n        [ 54,  70,  75,  44,   9],\n        [ 31,  82,   8,  84, 116],\n        [110,  52,  32,  92,   5],\n        [ 45,   7,  64,  81, 109],\n        [ 33,   1,  94,  97, 102],\n        [ 49, 110,  12,  83,  92],\n        [ 47, 112,  54,  75,   9],\n        [ 70,  47,  75,  44,   9],\n        [114,  85,  89,  56, 106],\n        [ 85,  69,  55, 114, 106],\n        [116,   8,  27,  60,  93],\n        [ 20, 103,  23,   4,   7],\n        [ 18,  96,  24,   5,  92],\n        [104,  93,  80,  27,  57],\n        [  9, 117,  75,  44, 111],\n        [108,  79,  18,  28,  96],\n        [  8,  48,  31, 116,  84],\n        [ 45,  72, 109,  90,  15],\n        [  0,  29,  80,  11,  87],\n        [ 77, 113,  97,  73, 102],\n        [112, 100,  26,  53,   9],\n        [ 76,  25,  37,   2, 115],\n        [ 56,  85, 106,  55, 114],\n        [ 54,  47,  75,  44,  91],\n        [ 15,  81,  10,  40,  95],\n        [ 64,  45,  90, 109,  15],\n        [ 66,  97,  43, 113,  33],\n        [ 81,  44,  10,  36,  71],\n        [  9,  44,  54,  47,  70],\n        [ 68,  37,  25, 102,  88],\n        [102, 113,  66,  97,  84],\n        [ 42,  88, 110,  52,  12],\n        [108,  28,  62,  18, 101],\n        [ 29,  27, 104,   0,  60],\n        [ 74,  10,  44,  71,  36],\n        [ 31,  48,   8,  84,  11],\n        [ 96,  52,  92,  49, 101],\n        [  8, 113,  48,  31,  77],\n        [ 56,  55, 106,  69, 114],\n        [107,  85, 106,   3,  56],\n        [ 98,   0,  11,  27, 116],\n        [ 42,  12, 110,  52,  25],\n        [104,  93, 114,  80,  60],\n        [ 45, 109,  64,   7,   4],\n        [ 10,  19,  70,  81,  74],\n        [  5, 119,  49,  96,  52],\n        [104,  60,  22,  27,  57],\n        [ 51,  97,   1, 102,  77],\n        [  4,   7,  71, 103,  15],\n        [ 83,  18,  92,   5, 119],\n        [ 51,  94,  77,  66, 102],\n        [ 87,  11,  27,  82,  60],\n        [118,  34,  13,   6,  35],\n        [ 26,   9,  75,  38,  47],\n        [ 83,  52,  96,  24,  49],\n        [ 77, 113,  97,  76,  66],\n        [ 20,   4,   7,  95,  23],\n        [ 93,  27,  60,  22,  80],\n        [  5,  92,  49,  21, 119],\n        [114,  85,  89,  55,  56],\n        [ 86,  85,   3, 106,  56],\n        [ 79,  62,  28,  18,  59],\n        [ 45,  90,  64,   7,   4],\n        [ 32,  49,  52,  88,  92],\n        [117,  44,   9,  74,  75],\n        [ 53,  67, 100,   9,  75],\n        [ 77,  84, 102,  66,  97],\n        [ 55,  89, 106,  85,  56],\n        [  2,  17,  68,  34,  76],\n        [  8,  57,  48,  84,  80],\n        [111,  44,  61,   9,  74],\n        [ 41,  99,  34,  21,   2],\n        [ 92,   5,  49,  96,  52]], dtype=int64))"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.kneighbors()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
